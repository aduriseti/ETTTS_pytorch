{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge librosa\n",
    "\n",
    "# !conda install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import string\n",
    "import librosa\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(ch.nn.Module):\n",
    "    def __init__(self,o,i,k,d,causal,s=1):\n",
    "        super(C,self).__init__()\n",
    "        self.causal = causal\n",
    "        assert (k-1)%2 == 0 \n",
    "        if causal:\n",
    "            self.pad = (k-1)*d\n",
    "        else:\n",
    "#             print('filter',k,'dilation',d,'total pad',(k-1)*d,'half pad',(k-1)*d//2)\n",
    "            self.pad = (k-1)*d // 2 \n",
    "        self.conv = ch.nn.Conv1d(out_channels=o, in_channels=i,\n",
    "                    kernel_size=k, dilation=d, stride=s, padding=self.pad)\n",
    "        ch.nn.init.kaiming_normal_(self.conv.weight.data)\n",
    "        self.dilation = d\n",
    "    \n",
    "    def forward(self,X):\n",
    "        O = self.conv(X)\n",
    "        return O[:,:,:-self.pad] if self.causal and self.pad else O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cs(ch.nn.Module):\n",
    "    def __init__(self,o,i,k,d,causal,s=1):\n",
    "        super(C,self).__init__()\n",
    "        self.causal = causal\n",
    "        assert (k-1)%2 == 0 \n",
    "        if causal:\n",
    "            self.pad = (k-1)*d\n",
    "        else:\n",
    "            self.pad = (k-1)*d // 2 \n",
    "#         self.conv = ch.nn.Conv1d(out_channels=o, in_channels=i,\n",
    "#                     kernel_size=k, dilation=d, stride=s, padding=pad)\n",
    "        self.depthwise = ch.nn.Conv1d(out_channels=i, in_channels=i,\n",
    "                        kernel_size=k, dilation=d, stride=s,\n",
    "                        padding=self.pad, groups=i)\n",
    "        self.pointwise = ch.nn.Conv1d(out_channels=o, in_channels=i,kernel_size=1)\n",
    "        ch.nn.init.kaiming_normal_(self.depthwise.weight.data)\n",
    "        ch.nn.init.kaiming_normal_(self.pointwise.weight.data)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        O = self.pointwise(self.depthwise(X))\n",
    "        return O[:,:,:-self.pad] if self.causal else O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Css(ch.nn.Module):\n",
    "    def __init__(self,o,i,k,d,causal,s=1):\n",
    "        super(C,self).__init__()\n",
    "        self.causal = causal\n",
    "        assert (k-1)%2 == 0 \n",
    "        if causal:\n",
    "            self.pad = (k-1)*d\n",
    "        else:\n",
    "            self.pad = (k-1)*d // 2 \n",
    "#         self.conv = ch.nn.Conv1d(out_channels=o, in_channels=i,\n",
    "#                     kernel_size=k, dilation=d, stride=s, padding=pad)\n",
    "        self.depthwise = ch.nn.Conv1d(out_channels=i, in_channels=i,\n",
    "                        kernel_size=k, dilation=d, stride=s,\n",
    "                        padding=self.pad, groups=i)\n",
    "        self.pointwise = ch.nn.Conv1d(out_channels=o, in_channels=i,\n",
    "                                      kernel_size=1, groups=4)\n",
    "        ch.nn.init.kaiming_normal_(self.depthwise.weight.data)\n",
    "        ch.nn.init.kaiming_normal_(self.pointwise.weight.data)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        O = self.pointwise(self.depthwise(X))\n",
    "        return O[:,:,:-self.pad] if self.causal else O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = C(8,4,3,1,0)\n",
    "conv(ch.rand(3,4,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(ch.nn.Module):\n",
    "    def __init__(self,o,i,k,d,causal=0,s=2):\n",
    "        super(D,self).__init__()\n",
    "        self.tconv = ch.nn.ConvTranspose1d(out_channels=o, in_channels=i, \n",
    "                       kernel_size=k, dilation=d, stride=s)\n",
    "        ch.nn.init.kaiming_normal_(self.tconv.weight.data)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return self.tconv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HC(ch.nn.Module):\n",
    "    def __init__(self,o,i,k,d,causal,s=1):\n",
    "        assert o == i\n",
    "        super(HC,self).__init__()\n",
    "        self.o = o\n",
    "        self.conv = C(2*o,i,k,d,causal,s)\n",
    "\n",
    "    def forward(self,X):\n",
    "        H = self.conv(X)\n",
    "        H1,H2 = H[:,:self.o,:],H[:,self.o:,:]\n",
    "        G = ch.sigmoid(H1)\n",
    "        return G*H2 + (1-G)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEnc(ch.nn.Module):\n",
    "    def __init__(self,d,e,c2i):\n",
    "        super(TextEnc,self).__init__()\n",
    "        c = 0 # non causal\n",
    "        self.embed = ch.nn.Embedding(len(c2i),e)\n",
    "        ch.nn.init.kaiming_normal_(self.embed.weight.data)\n",
    "        layers = [C(2*d,e,1,1,c),ch.nn.ReLU(),C(2*d,2*d,1,1,c)]\n",
    "        for _ in range(2):\n",
    "            layers += [HC(2*d,2*d,3,3**ldf,c) for ldf in range(4)]\n",
    "        layers += [HC(2*d,2*d,3,1,c) for _ in range(2)]\n",
    "        layers += [HC(2*d,2*d,1,1,c) for _ in range(2)]\n",
    "        self.seq = ch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,L):\n",
    "        # permute b/c next layer expects dims to be [batch,embed,seq]\n",
    "        # output of embed layer is [batch,seq,embed]\n",
    "#         print(L.shape,self.embed(L).shape)\n",
    "#         print(self.embed(L).permute(0,2,1).shape)\n",
    "        return self.seq(self.embed(L).permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioEnc(ch.nn.Module):\n",
    "    def __init__(self,d,F):\n",
    "        super(AudioEnc,self).__init__()\n",
    "        c = 1 # causal\n",
    "        layers = [C(d,F,1,1,c),ch.nn.ReLU(),C(d,d,1,1,c),ch.nn.ReLU(),C(d,d,1,1,c)]\n",
    "        for _ in range(2):\n",
    "            layers += [HC(d,d,3,3**ldf,c) for ldf in range(4)]\n",
    "        layers += [HC(d,d,3,3,c) for _ in range(2)]\n",
    "        self.seq = ch.nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,S):\n",
    "        return self.seq(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2Mel(ch.nn.Module):\n",
    "    def __init__(self,d,e,c2i,F):\n",
    "        super(Text2Mel,self).__init__()\n",
    "        self.d = d\n",
    "        self.textEnc = TextEnc(d,e,c2i)\n",
    "        self.audioEnc = AudioEnc(d,F)\n",
    "    \n",
    "    def forward(self,L,S):\n",
    "        KV = self.textEnc(L)\n",
    "        K,V = KV[:,:self.d,:],KV[:,self.d:,:]\n",
    "        Q = self.audioEnc(S[:,:,:])\n",
    "#         print('K',K.shape,'V',V.shape,'Q',Q.shape)\n",
    "        A = ch.nn.Softmax(dim=1)(ch.matmul(ch.transpose(K,-1,-2),Q) / self.d**0.5)\n",
    "        R = ch.matmul(V,A)\n",
    "#         print('R',R.shape,'Q',Q.shape)\n",
    "        return ch.cat([R,Q],dim=1),A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDec(ch.nn.Module):\n",
    "    def __init__(self,d,F):\n",
    "        super(AudioDec,self).__init__()\n",
    "        s = 1 # causal\n",
    "        layers = [C(d,2*d,1,1,s)]\n",
    "        for _ in range(1): #?\n",
    "            layers += [HC(d,d,3,3**ldf,s) for ldf in range(4)]\n",
    "        layers += [HC(d,d,3,1,s) for _ in range(2)]\n",
    "        for _ in range(3): \n",
    "            layers += [C(d,d,1,1,s),ch.nn.ReLU()]\n",
    "        layers += [C(F,d,1,1,s),ch.nn.Sigmoid()]\n",
    "        self.seq = ch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,Rp):\n",
    "        return self.seq(Rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSRN(ch.nn.Module):\n",
    "    def __init__(self,c,F,Fp):\n",
    "        super(SSRN,self).__init__()\n",
    "        s = 0 # non causal\n",
    "        layers = [C(c,F,1,1,s)]\n",
    "        for _ in range(1): #?\n",
    "            layers += [HC(c,c,3,1,s),HC(c,c,3,3,s)]\n",
    "        for _ in range(2):\n",
    "            layers += [D(c,c,2,1),HC(c,c,3,1,s),HC(c,c,3,3,s)]\n",
    "        layers += [C(2*c,c,1,1,s)]\n",
    "        layers += [HC(2*c,2*c,3,1,s) for _ in range(2)]\n",
    "        layers += [C(Fp,2*c,1,1,s)]\n",
    "        for _ in range(2):\n",
    "            layers += [C(Fp,Fp,1,1,s),ch.nn.ReLU()]\n",
    "        layers += [C(Fp,Fp,1,1,s),ch.nn.Sigmoid()]\n",
    "        self.seq = ch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,Y):\n",
    "        return self.seq(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv = C(3,2,3,1,0)\n",
    "# tconv = D(3,2,2,1,2)\n",
    "# hconv = HC(2,2,3,1,0)\n",
    "# I.shape,conv(I).shape,tconv(I).shape,hconv(I).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 256;e=128;c2i=[0]*26;c=512;F=80;Fp=513\n",
    "# Fp = 516\n",
    "alpha = 0.5\n",
    "d=int(d*alpha); e=int(e*alpha); c=int(c*alpha)\n",
    "textEnc = TextEnc(d=d,e=e,c2i=c2i)\n",
    "audioEnc = AudioEnc(d=d,F=F)\n",
    "audioDec = AudioDec(d=d,F=F)\n",
    "ssrn = SSRN(c=c,F=F,Fp=Fp)\n",
    "text2Mel = Text2Mel(d=d,e=e,c2i=datasets.LJSpeechDataset().alpha,F=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text2Mel.cuda()\n",
    "# audioDec.cuda()\n",
    "# ssrn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4284544, 1028992, 684112, 6979335, 5313856]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha = 0.5, super-separable\n",
    "[sum(np.prod(p.size()) for p in m.parameters()) for m in (textEnc,audioEnc,audioDec,ssrn,text2Mel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbinLoss(ch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DbinLoss,self).__init__()\n",
    "    \n",
    "    def forward(self,Yhat,Y):\n",
    "        EPS = 1e-12\n",
    "        elLoss = -(Y*ch.log(Yhat+EPS)+(1-Y)*ch.log(1-Yhat+EPS))\n",
    "#         return elLoss.view(elLoss.shape[0],-1).mean(1)\n",
    "        return elLoss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAttLoss(ch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAttLoss,self).__init__()\n",
    "            \n",
    "    def forward(self,A):\n",
    "        _,N,T = A.shape\n",
    "        W = ch.Tensor([[np.e**(-(n/N-t/T)**2 / (2*g**2)) \n",
    "                        for t in range(1,T+1)] \n",
    "                       for n in range(1,N+1)])\n",
    "        return ((1-W)*A).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1Fun = ch.nn.L1Loss()\n",
    "BCEFun = ch.nn.BCELoss()\n",
    "def MelFun(Shat,S): return L1Fun(Shat,S) + BCEFun(Shat,S)\n",
    "DbinFun = DbinLoss()\n",
    "GAttFun = GAttLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "init_lr=2e-4\n",
    "g=0.2\n",
    "b1 = 0.5\n",
    "b2 = 0.9\n",
    "eps = 1e-6\n",
    "logevery = 200\n",
    "dropout_rate = 0.1\n",
    "masking = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = ch.FloatTensor\n",
    "# dtype = ch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "ch.multiprocessing.set_start_method(\"spawn\",force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from importlib import reload\n",
    "reload(datasets)\n",
    "\n",
    "text2MelLoader = Data.DataLoader(datasets.LJSpeechDataset(ttmel=1),\n",
    "                                 batch_size=16,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=8)\n",
    "ttMelOpt = ch.optim.Adam(set(text2Mel.parameters())|set(audioDec.parameters()),\n",
    "                          lr=lr,betas=(b1,b2),eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31e9fd2a7d34b7ea4ed77ab818f2a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for step,(batchL,batchS,_) in tqdm.tqdm_notebook(enumerate(text2MelLoader)):\n",
    "        batchL = batchL.cuda()\n",
    "        batchS = batchS.cuda()\n",
    "        bL = ch.autograd.Variable(batchL)\n",
    "        bS = ch.autograd.Variable(batchS)\n",
    "        Rp,A = text2Mel(bL,bS)\n",
    "        Shat = audioDec(Rp)\n",
    "        melloss = MelFun(Shat[:,:,:-1],bS[:,:,1:])\n",
    "        attloss = GAttFun(A)\n",
    "        loss = melloss + attloss\n",
    "        ttMelOpt.zero_grad()\n",
    "        loss.backward()\n",
    "        ttMelOpt.step()\n",
    "#         if step % 100 == 0: \n",
    "#             print('step',step,'total',loss.data.item(),\n",
    "#                   'mel',melloss.data.item(),'att',attloss.data.item())\n",
    "#         if step % 100 == 0:\n",
    "#             plt.imshow(bS[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "#             plt.imshow(Shat[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "#             plt.imshow(A[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "    print('step',step,'total',loss.data.item(),\n",
    "          'mel',melloss.data.item(),'att',attloss.data.item())\n",
    "    plt.imshow(bS[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(Shat[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(A[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from importlib import reload\n",
    "reload(datasets)\n",
    "\n",
    "ssrnLoader = Data.DataLoader(datasets.LJSpeechDataset(ttmel=0),\n",
    "                             batch_size=16,\n",
    "                             shuffle=True,\n",
    "                             num_workers=8)\n",
    "ssrnOpt = ch.optim.Adam(ssrn.parameters(),lr=lr,betas=(b1,b2),eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for step,(_,batchS,batchY) in tqdm.tqdm_notebook(enumerate(ssrnLoader)):\n",
    "        batchS = batchS.cuda()\n",
    "        batchY = batchY.cuda()\n",
    "        bS = ch.autograd.Variable(batchS)\n",
    "        bY = ch.autograd.Variable(batchY)\n",
    "        Yhat = ssrn(bS)\n",
    "        loss = MelFun(Yhat,bY)\n",
    "        ssrnOpt.zero_grad()\n",
    "        loss.backward()\n",
    "        ssrnOpt.step()\n",
    "#         if step % 100 == 0: \n",
    "#             print('step',step,'loss',loss.data.item())\n",
    "#         if step % 100 == 0:\n",
    "#             plt.imshow(bS[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "#             plt.imshow(bY[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "#             plt.imshow(Yhat[0].cpu().detach().numpy(),cmap='gray')\n",
    "#             plt.show()\n",
    "    print('step',step,'loss',loss.data.item())\n",
    "    plt.imshow(bS[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(bY[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(Yhat[0].cpu().detach().numpy(),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C(\n",
       "  (conv): Conv1d(2, 1, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C(1,2,3,4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-282-960c27f0bd3e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-282-960c27f0bd3e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensor(0.4850, grad_fn=<L1LossBackward>)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor(0.4850, grad_fn=<L1LossBackward>)\n",
    "tensor(0.4834, grad_fn=<L1LossBackward>)\n",
    "tensor(0.4792, grad_fn=<L1LossBackward>)\n",
    "tensor(0.4764, grad_fn=<L1LossBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "a8160a83e8904bca82a2c3ceae6a2b65": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "ac14f9c0dea54a57b9ef0ad30780d2b0": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
