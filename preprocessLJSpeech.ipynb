{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import string\n",
    "import librosa\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = '../LJSpeech-1.1'\n",
    "csvpath = os.path.join(root,'metadata.csv')\n",
    "wavdir = os.path.join(root,'wavs')\n",
    "meldir = os.path.join(root,'mels')\n",
    "fftdir = os.path.join(root,'ffts')\n",
    "txtdir = os.path.join(root,'txts')\n",
    "if not os.path.exists(meldir):\n",
    "    os.makedirs(meldir)\n",
    "if not os.path.exists(fftdir):\n",
    "    os.makedirs(fftdir)\n",
    "if not os.path.exists(txtdir):\n",
    "    os.makedirs(txtdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha = string.ascii_lowercase + '?!:;,.- \\\"()'+'\\n'+\"'\"\n",
    "alpha = string.ascii_lowercase + ',.- \\\"'\n",
    "i2c = dict(enumerate(alpha))\n",
    "c2i = dict((c,i) for i,c in enumerate(alpha))\n",
    "alpha = set(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nFFT = 1024\n",
    "hopL = 256\n",
    "nMel = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(csvpath) as F:\n",
    "    lines = F.read().split('\\n')\n",
    "    print(len(lines))\n",
    "    \n",
    "split = [l.split('|') for l in lines]\n",
    "split = [s for s in split if len(s) == 3]\n",
    "split = [(duid,_,dtxt.lower()) for duid,_,dtxt in split]\n",
    "print(len(split))\n",
    "valid = [(duid,_,dtxt) for duid,_,dtxt in split \n",
    "         if sum(c in alpha for c in dtxt) == len(dtxt)]\n",
    "\n",
    "# invalid = [(duid,_,dtxt) for duid,_,dtxt in split \n",
    "#          if \"\".join(c for c in dtxt if c in alpha) != dtxt]\n",
    "print(len(valid))\n",
    "#     print()\n",
    "#     print(\"\\n\".join(str(s) for s in valid[:3]))\n",
    "# print()\n",
    "# print(\"\\n\".join(str(s) for s in invalid[:3]))\n",
    "\n",
    "np.random.seed(0)\n",
    "ridx = np.random.choice(range(len(valid)),1000)\n",
    "valid = np.array(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for duid,_,dtxt in tqdm.tqdm_notebook(valid[ridx]):\n",
    "    wavpath = os.path.join(wavdir,duid+'.wav')\n",
    "    melpath = os.path.join(meldir,duid+'_mel')\n",
    "    fftpath = os.path.join(fftdir,duid+'_fft')\n",
    "    txtpath = os.path.join(txtdir,duid+'_txt')\n",
    "    L = np.load(txtpath+'.npy')\n",
    "    S = np.load(melpath+'.npy')\n",
    "    Y = np.load(fftpath+'.npy')\n",
    "#     print(duid,'Y:',Y.shape,'S:',S.shape,'L:',L.shape)\n",
    "    shapes.append((L.shape,S.shape,Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Lshapes,Sshapes,Yshapes = zip(*shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Lshapes = np.array(Lshapes)\n",
    "Sshapes = np.array(Sshapes)\n",
    "Yshapes = np.array(Yshapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Lshapes.max(axis=0),Sshapes.max(axis=0),Yshapes.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for duid,_,dtxt in tqdm.tqdm_notebook(valid[ridx]):\n",
    "    wavpath = os.path.join(wavdir,duid+'.wav')\n",
    "    melpath = os.path.join(meldir,duid+'_mel')\n",
    "    fftpath = os.path.join(fftdir,duid+'_fft')\n",
    "    txtpath = os.path.join(txtdir,duid+'_txt')\n",
    "    \n",
    "    if not sum(not os.path.exists(path+'.npy') for path in (melpath,fftpath,txtpath)): continue\n",
    "\n",
    "    audio,rate = librosa.load(wavpath)\n",
    "\n",
    "    gamma,eta = 0.6,1.3\n",
    "    Y = librosa.core.stft(audio,n_fft=nFFT,hop_length=hopL)\n",
    "    # print('total phase:', np.sum(np.abs(np.angle(Y)))) # confirm phase in stft\n",
    "    Y = Y[:,:Y.shape[1]//4 * 4] # normalize length to mult of 4\n",
    "    Y = np.abs(Y) # get stft magnitude\n",
    "    Y = (Y/np.max(Y))**gamma # normalize w/ preemphasis factor gamma\n",
    "    Y = Y.astype('f')\n",
    "    np.save(fftpath,Y)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(audio,n_fft=nFFT,hop_length=hopL,n_mels=nMel)\n",
    "    S = S[:,3::4]  # b/c deconv non causal??\n",
    "    S = (S/np.max(S))**gamma\n",
    "    S = S.astype('f')\n",
    "    np.save(melpath,S)\n",
    "\n",
    "    L = np.array([c2i[c] for c in dtxt])\n",
    "    L = L.astype('i')\n",
    "    np.save(txtpath,L)\n",
    "\n",
    "    print(duid,'Y:',Y.shape,'S:',S.shape,'L:',L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as ch\n",
    "import torch.utils.data as Data\n",
    "import librosa\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "class LJSpeechDataset(Data.Dataset):\n",
    "    def __init__(self,root = '../LJSpeech-1.1',ttmel=1):\n",
    "        self.ttmel = ttmel\n",
    "        self.csvpath = os.path.join(root,'metadata.csv')\n",
    "        self.wavdir = os.path.join(root,'wavs')\n",
    "        \n",
    "        # alpha = string.ascii_lowercase + '?!:;,.- \\\"()'+'\\n'+\"'\"\n",
    "        self.alpha = string.ascii_lowercase + ',.- \\\"'\n",
    "        self.i2c = dict((i+1,c) for i,c in enumerate(self.alpha))\n",
    "        self.c2i = dict((c,i+1) for i,c in enumerate(self.alpha))\n",
    "        self.alpha = set(self.alpha)\n",
    "        \n",
    "        with open(self.csvpath) as F:\n",
    "            lines = F.read().split('\\n')\n",
    "\n",
    "        split = [l.split('|') for l in lines]\n",
    "        split = [s for s in split if len(s) == 3]\n",
    "        split = [(duid,_,dtxt.lower()) for duid,_,dtxt in split]\n",
    "        self.valid = [(duid,_,dtxt) for duid,_,dtxt in split \n",
    "                 if sum(c in self.alpha for c in dtxt) == len(dtxt)]\n",
    "        self.valid = np.array(self.valid)\n",
    "        \n",
    "#         # Lshapes.max(axis=0),Sshapes.max(axis=0),Yshapes.max(axis=0)\n",
    "#         #(array([180]), array([ 80, 217]), array([513, 868]))\n",
    "#         self.Llen = 180\n",
    "#         self.Slen = 217\n",
    "#         self.Ylen = 868\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.valid)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        duid,_,dtxt = self.valid[idx]\n",
    "        wavpath = os.path.join(self.wavdir,duid+'.wav')\n",
    "\n",
    "        nFFT = 1024\n",
    "        hopL = 256\n",
    "        nMel = 80\n",
    "        gamma,eta = 0.6,1.3\n",
    "        # Lshapes.max(axis=0),Sshapes.max(axis=0),Yshapes.max(axis=0)\n",
    "        #(array([180]), array([ 80, 217]), array([513, 868]))\n",
    "        Lshape = (180,)\n",
    "        Sshape = (80,217)\n",
    "        Yshape = (513,868)\n",
    "        \n",
    "        def padZero(tensor,targetLen):\n",
    "            if tensor.shape[-1] >= targetLen: return tensor[...,:targetLen]\n",
    "            padDim = list(tensor.shape)\n",
    "            padDim[-1] = max(0,targetLen-padDim[-1])\n",
    "            return ch.cat((tensor.type(ch.float),\n",
    "                           ch.zeros(*padDim).type(ch.float)),\n",
    "                          dim=-1)\n",
    "\n",
    "        \n",
    "        audio,rate = librosa.load(wavpath)\n",
    "        \n",
    "        Y = librosa.core.stft(audio,n_fft=nFFT,hop_length=hopL)\n",
    "        # print('total phase:', np.sum(np.abs(np.angle(Y)))) # confirm phase in stft\n",
    "        Y = Y[:,:Y.shape[1]//4 * 4] # normalize length to mult of 4\n",
    "        Y = np.abs(Y) # get stft magnitude\n",
    "        Y = (Y/np.max(Y))**gamma # normalize w/ preemphasis factor gamma    \n",
    "\n",
    "        S = librosa.feature.melspectrogram(audio,n_fft=nFFT,hop_length=hopL,n_mels=nMel)\n",
    "        S = S[:,3::4]  # b/c deconv non causal??\n",
    "        S = (S/np.max(S))**gamma\n",
    "        \n",
    "        if self.ttmel: #txt2mel\n",
    "            S = padZero(ch.from_numpy(S),217)\n",
    "            Y = padZero(ch.from_numpy(Y),868)\n",
    "        else: #ssrn trains in batches of 64 to save mem\n",
    "            if S.shape[1] > 64:\n",
    "                i = np.random.randint(0,S.shape[1]-64+1)\n",
    "                S = ch.from_numpy(S[:,i:i+64])\n",
    "                Y = ch.from_numpy(Y[:,4*i:4*i+256])\n",
    "            else:\n",
    "                S = padZero(ch.from_numpy(S),64)\n",
    "                Y = padZero(ch.from_numpy(Y),256)\n",
    "        S = S.type(ch.float)\n",
    "        Y = Y.type(ch.float)\n",
    "        \n",
    "\n",
    "        L = np.array([self.c2i[c] for c in dtxt])\n",
    "        L = padZero(ch.from_numpy(L),180)\n",
    "        L = L.type(ch.long)\n",
    "\n",
    "        return L,S,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = LJSpeechDataset(ttmel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L,S,Y = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 180]), torch.Size([80, 64]), torch.Size([513, 256]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape,S.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
